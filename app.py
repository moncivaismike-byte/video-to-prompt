import streamlit as st
import cv2
from PIL import Image
import requests
import base64
import io

st.set_page_config(page_title="Nano Banana è§†é¢‘è§£æ", layout="wide")

st.title("ğŸ¬ Nano Banana è§†é¢‘é•œå¤´ AI æŠ½å¸§å·¥å…·")

# ä¾§è¾¹æ ï¼šé…ç½®
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("è¾“å…¥ Nano Banana API Key", type="password")
    gap = st.slider("æŠ½å¸§é¢‘ç‡ (æ¯ç§’å‡ å¸§)", 0.5, 5.0, 1.0)

file = st.file_uploader("ä¸Šä¼ è§†é¢‘ (MP4/MOV)", type=["mp4", "mov"])

def analyze_frame(image, key):
    # è¿™é‡Œæ˜¯è°ƒç”¨ Nano Banana æ¥å£çš„æ ‡å‡†é€»è¾‘
    # æ³¨æ„ï¼šå®é™… URL è¯·æ›¿æ¢ä¸º Nano Banana å®˜æ–¹æä¾›çš„ Endpoint
    api_url = "https://api.nanobanana.com/v1/vision" 
    
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    payload = {
        "model": "nano-banana-vision",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "è¯·è¯¦ç»†æè¿°æ­¤ç”»é¢ï¼Œå¹¶ç”Ÿæˆä¸€æ®µé«˜è´¨é‡çš„ AI ç»˜å›¾æç¤ºè¯ (Prompt)"},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_str}"}}
            ]
        }]
    }
    try:
        response = requests.post(api_url, json=payload, headers=headers)
        return response.json()['choices'][0]['message']['content']
    except:
        return "API è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Key æˆ–ç½‘ç»œã€‚"

if file and api_key:
    with open("temp.mp4", "wb") as f:
        f.write(file.read())
    
    cap = cv2.VideoCapture("temp.mp4")
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    if st.button("ğŸš€ å¼€å§‹ AI æ‹†è§£åˆ†æ"):
        count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            if count % int(fps / gap) == 0:
                img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                col1, col2 = st.columns([1, 2])
                with col1: st.image(img)
                with col2:
                    result = analyze_frame(img, api_key)
                    st.write("**AI è§£æç»“æœï¼š**")
                    st.info(result)
                st.divider()
            count += 1
        cap.release()
