import streamlit as st
import cv2
from PIL import Image
import requests
import base64
import io

st.set_page_config(page_title="AIè§†é¢‘åˆ†é•œä¸“å®¶", layout="wide")
st.title("ğŸ¬ è§†é¢‘é•œå¤´ AI æ·±åº¦æ‹†è§£ (ç¨³å®šç‰ˆ)")

with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    api_key = st.text_input("è¾“å…¥çµå…‰APIä»¤ç‰Œ", type="password")
    model_name = st.text_input("æ¨¡å‹åç§°", value="gpt-4o-mini")
    gap = st.slider("æŠ½å¸§é¢‘ç‡ (ç§’/å¸§)", 1.0, 10.0, 5.0)

uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=["mp4", "mov"])

def analyze_single_frame(image, key, model):
    buffered = io.BytesIO()
    # å…³é”®ï¼šå‹ç¼©è´¨é‡åˆ° 60%ï¼Œå‡å°ä½“ç§¯ï¼Œæå¤§åŠ å¿«ä¸Šä¼ é€Ÿåº¦
    image.save(buffered, format="JPEG", quality=60) 
    img_str = base64.b64encode(buffered.getvalue()).decode()
    
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": "ç®€è¦æè¿°ç”»é¢å¹¶æä¾›AIç»˜å›¾Prompt"},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_str}"}}
            ]
        }]
    }
    try:
        # è®¾ç½®ä¸¥æ ¼è¶…æ—¶ï¼Œé˜²æ­¢æ— é™ç­‰å¾…
        response = requests.post("https://api.lingguang.ai/v1/chat/completions", json=payload, headers=headers, timeout=20)
        return response.json()['choices'][0]['message']['content']
    except Exception:
        return "âš ï¸ è¯¥å¸§è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨å¤„ç†ä¸‹ä¸€å¸§..."

if uploaded_file and api_key:
    if st.button("ğŸš€ å¼€å§‹é€å¸§è§£æ"):
        with open("temp.mp4", "wb") as f:
            f.write(uploaded_file.read())
        
        cap = cv2.VideoCapture("temp.mp4")
        fps = cap.get(cv2.CAP_PROP_FPS)
        count = 0
        frame_idx = 1
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            if count % int(fps * gap) == 0:
                img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.image(img, caption=f"é•œå¤´ {frame_idx}")
                with col2:
                    with st.spinner(f"æ­£åœ¨åˆ†æç¬¬ {frame_idx} ä¸ªé•œå¤´..."):
                        res = analyze_single_frame(img, api_key, model_name)
                        st.info(res)
                frame_idx += 1
            count += 1
        cap.release()
        st.success("âœ¨ æ‰€æœ‰é•œå¤´åˆ†æå®Œæˆï¼")
